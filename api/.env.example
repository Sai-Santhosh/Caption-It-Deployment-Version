# Caption-It API - Production Configuration
# Copy to .env and customize

# Inference: "huggingface" (HF API) or "local" (PyTorch)
INFERENCE_MODE=huggingface

# Local model path (when INFERENCE_MODE=local)
MODEL_PATH=./models/caption-it

# Hugging Face (when INFERENCE_MODE=huggingface)
HF_MODEL_ID=nlpconnect/vit-gpt2-image-captioning
HF_API_TOKEN=
HF_API_URL=

# Generation
MAX_SEQ_LEN=24
NUM_BEAMS=4

# API
CORS_ORIGINS=*
MAX_UPLOAD_MB=10
REQUEST_TIMEOUT_SECONDS=30
